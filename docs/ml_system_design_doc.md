# Документ для разработки MVP: Персонализированные рекомендации образовательных курсов

---

## Термины и пояснения

- **Итерация** — совокупность всех работ, проводимых до старта очередного пилота.  
- **БТ (бизнес-требования)** — требования, определяющие основные цели проекта и ограничения.  
- **EDA (Exploratory Data Analysis)** — исследовательский анализ данных, направленный на изучение и предварительную обработку данных.  
- **Роли**:  
  - **Product Owner** — отвечает за постановку бизнес-целей, разработку требований и оценку успеха.  
  - **Data Scientist** — совмещает функции исследователя данных, ML-инженера и ML Ops-специалиста для разработки и продуктивизации моделей.  
- Распределение ролей может варьироваться в зависимости от операционной модели вашей организации.

---

## 1. Цели и предпосылки

### 1.1. Зачем идем в разработку продукта?

#### Бизнес-цель (Product Owner):  
Привлечь аудиторию на платформу образовательных курсов с помощью инструмента, который подбирает пользователю курс на основе требований вакансии и текущего опыта пользователя. Для этого будут использованы инструменты NLP и классического ML для мэтчинга скиллов вакансий с курсами и их стеком, а также другими сущностями. Это позволит повысить интерес аудитории и, в перспективе, привлечь рекламу и монетизировать платформу.

#### Почему станет лучше (Product Owner & Data Scientist):  
- Повысится вовлечённость пользователей за счёт персонализированных рекомендаций, основанных на мэтчинге скиллов вакансий и стека курсов.
- Платформа станет инструментом карьерного роста, что усилит её конкурентоспособность.  
- Алгоритм подстраивается под интерес пользователя к конкретной вакансии, предоставляя наиболее релевантный курс для освоения необходимых скиллов, исходя из схожести требований вакансии.
- Бизнес получит возможность демонстрировать аудитории актуальные курсы, стимулируя спрос.  

#### Успех итерации с точки зрения бизнеса (Product Owner):  
- Улучшение вовлечённости лидов и повышение их интереса к платформе.  
- Высокая удовлетворённость пользователей предложенными рекомендациями.  

---

### 1.2. Бизнес-требования и ограничения

#### Краткое описание БТ (Product Owner):  
- Автоматизация анализа вакансий с сайтов вакансий.  
- Генерация релевантных рекомендаций образовательных курсов на основе сходства навыков в вакансии и резюме.  
 

#### Бизнес-ограничения (Product Owner):  
- Ограничение на бюджет MVP.  
- Максимальная скорость обработки запросов.  

#### Ожидания от итерации (Product Owner):  
- Завершение тестирования MVP.  
- Подготовка базы для масштабирования функционала и интеграции рекламы.  

#### Описание бизнес-процесса пилота (Product Owner):  
- Пользователь отправляет ссылку вакансии и своего резюме → система анализирует требования → выдаёт список подходящих курсов с платформы.  
- На основе рекомендаций отслеживается поведение пользователей (например, переходы на курсы).  

#### Успех пилота (Product Owner):  
- Успешное тестирование рекомендаций с валидированной точностью.  
- Готовность функционала систем для интеграции курсов разных образовательных платформ.  
- Подготовка к масштабированию решения на дополнительные источники данных.  

---

### 1.3. Что входит в скоуп проекта/итерации, что не входит

#### Входит (Data Scientist):  
- Построение базовой модели анализа вакансий.  
- Разработка MVP для тестирования рекомендаций.  
- Документирование всех процессов для дальнейшего развития.  

#### Не входит (Data Scientist):  
- Полная интеграция рекламы (в случае если проект будет интересен рекламодателям (образовательные платформы)).  
- Детальная настройка пользовательского интерфейса.  

#### Описание результата (Data Scientist):  
- Воспроизводимое решение, готовое для масштабирования.  

#### Технический долг (Data Scientist):  
- Оптимизация производительности.  
- Разработка модулей для расширения функционала.  

---

### 1.4. Предпосылки решения

#### Общие предпосылки (Data Scientist):  
- Данные: текст вакансий (HH.ru, superjob и тд) и описание курсов (GeekBrains).  
- Горизонт прогноза: мгновенная выдача рекомендаций.  
- Гранулярность модели: на уровне отдельного пользователя.  

---

## 2. Методология

### 2.1. Постановка задачи (Data Scientist)  
- Построение рекомендательной системы для образовательной платформы.  
- Анализ требований вакансий и сопоставление их с описанием курсов.  

---

### 2.2. Блок-схема решения (Data Scientist)  

#### Основные этапы:  
1. **Сбор данных**:  
   - Извлечение вакансий с сайта вакансий.  
   - Сбор информации о курсах с платформы GeekBrains.  

2. **Обработка данных**:  
   - Исследовательский анализ данных (EDA).  
   - Преобразование текстов вакансий и курсов (токенизация, векторизация).  

3. **Модель**:  
   - NLP-алгоритмы для анализа текста.  
   - Рекомендательная система на основе сопоставления данных.  

4. **Тестирование**:  
   - Проверка качества рекомендаций (точность, релевантность).  
   - Сбор обратной связи от пользователей.  

5. **Закрытие технического долга**:  
   - Оптимизация кода.  
   - Подготовка к интеграции рекламного модуля.  
6. Блок схема:
![Схема работы программы](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/sheme.jpg)


---

### Этапы решения задачи

# Этап 1. EDA и Подготовка данных

### Описание данных/сущностей

Изначально данные собирались вручную с платформ HH.ru, superjob, rvr, rabota.ru (тексты вакансий) и GeekBrains (описания курсов). Данные из различных источников включают информацию о вакансиях, курсах и скиллах.

#### Данные:
1. **data_it.csv**:
    - Включает **171,140 записей** с информацией о вакансиях.
    - **31 колонка** с различной информацией о вакансиях, включая:
        - **Общая информация**: Источник данных, идентификаторы вакансий, дата публикации, статус вакансии.
        - **Информация о работодателе**: Название компании, отрасль, тип работодателя.
        - **Характеристики вакансии**: Описание, зарплата, требуемый опыт, навыки (hard_skills, soft_skills).
        - **Географическая информация**: Страна, регион, район.
        - **Категория и роль**: Категория вакансии, роль.

![sheme](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/columns_info.png)

  #### Объем данных:
    - Данные с конца 2022 до конца 2023 года собирались вручную, что ограничивало масштаб анализа.
    - С увеличением объема данных сбор стал занимать больше времени и ресурсов.

![publications_per_mnth](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/publications_per_mnth.png)

  #### Качество данных:
    - Пропуски в колонках:
      - `region_district_name` (13%), `role_name` (6.7%), `salary_currency` (18.3%).
    - Разнородность формата навыков (`skills`, `hard_skills`, `soft_skills`).
    - Неконсистентность данных о зарплатах (разные валюты, неоднозначность значений "от" и "до").

![nan_info](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/nan_info.png)

![nans_visualize](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/nans_visualize.png)

![salary_distribution](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/salary_distribution.png)

Имеем такие распределения по источникам данных, типу занятости, необходимому опыту и топ 10 вакансиям.

![source_distribution](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/source_distribution.png)

![source_distribution](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/shedule_distribution.png)

![exp_distribution](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/exp_distribution.png)

![jobs_top_10](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/jobs_top_10.png)


---

2. **preprocess_it.csv**:
    - Данные, относящиеся исключительно к hard и soft скиллам. Содержат информацию о навыках, требуемых для различных вакансий.
    Где name - наименование вакансии,
    description - описание вакансии,
    hard_skills - прописанные скиллы для вакансии.

  ```plaintext
  <class 'pandas.core.frame.DataFrame'>
  RangeIndex: 170832 entries, 0 to 170831
  Data columns (total 4 columns):
  #   Column       Non-Null Count   Dtype 
  ---  ------       --------------   ----- 
  0   Unnamed: 0   170832 non-null  int64 
  1   name         170832 non-null  object
  2   description  170832 non-null  object
  3   hard_skills  81237 non-null   object
  dtypes: int64(1), object(3)
  ```

3. **df_hh_res_all.csv**:
    - Включает **69161 записей** и 361 колонку, где:
        - 5 колонок типа `object`: зарплата, график работы, опыт, занятость, регион.
        - Остальные колонки — скиллы с флагами 0 или 1, указывающими на наличие скилла.
!['salary_hh_all'](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/salary_hh_all.png)

!['exp_hh'](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/exp_hh.png)

!['zanyatost_hh'](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/zanyatost_hh.png)

!['regions_hh'](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/regions_hh.png)

!['nans_vis_hh'](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/nans_vis_hh.png)





4. **trebovanyia_full_data.csv**:
    - **1022 записи** с размеченными текстами вакансий, где указано, является ли текст связанным с скиллами (1 — скиллы, 0 — не скиллы).
    - Структура данных:
        - **text**: текст вакансии.
        - **label**: метка (1 — скиллы, 0 — не скиллы).
![trebovaniya_opisanya](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/trebovaniya_opisanya.png)
![trebovaniya_counts](https://github.com/ErikWarapaeff/EduMatchAI/blob/hw_2/docs/pictures/trebovaniya_counts.png)


    Пример:
    ```plaintext
    RangeIndex: 1022 entries, 0 to 1021  
    Data columns (total 3 columns):
    #   Column      Non-Null Count  Dtype 
    ---  ------      --------------  ----- 
    0   Unnamed: 0  1022 non-null   int64 
    1   text        1022 non-null   object
    2   label       1022 non-null   int64 
    label
    1    525
    0    497
    Name: count, dtype: int64
    ```

---

### Процесс генерации данных

#### Источники данных:
- **HH.ru, superjob, rvr, rabota.ru**: вакансии собираются через ручные парсинг-скрипты, данные сохраняются в формате CSV.
- **GeekBrains**: информация о курсах загружается аналогичным образом.

#### Регулярность:
- Обновления данных были нерегулярными из-за ручного сбора. С увеличением объема данных потребуется автоматизировать процесс.

---

### Недостаточность данных

Для повышения качества рекомендаций курсов по вакансии необходимо:
- Расширить временной диапазон данных.
- Увеличить разнообразие вакансий и курсов, охватывающих больше отраслей и регионов.

---

### Риски:
- **Устаревшая информация в вакансиях по скиллам**.
- **Недостаточная детализация вакансий** (например, отсутствие описания роли).
- **Перекосы в данных** из-за различий в регионах, отраслях и компаниях.

---

# Этап 2: Классификация текста на наличие скиллов

## 1. Сбор и подготовка данных:
- **Датасет**: текстовые описания вакансий с лейблом, указывающим, является ли текст связанным с скиллами (1 - скиллы, 0 - не скиллы) из таблицы `trebovanyia_full_data.csv`.
- **Требования**: данные должны быть очищены от шума (стоп-слов, знаков препинания), текст должен быть приведен к единому виду (например, привести к нижнему регистру).

## 2. Предобработка текста:
- Приведение текста к нижнему регистру.
- Удаление стоп-слов, знаков препинания, чисел и ненужных символов.
- Лемматизация или стемминг для приведения слов к их базовой форме.
- **Требования**: обработка текста должна быть выполнена так, чтобы сохранялась максимальная смысловая нагрузка и исключались лишние элементы.

## 3. Векторизация текста:
- Преобразование текста в числовые данные с использованием **TF-IDF** (или **Word2Vec** для более сложных моделей).
- **Требования**: метод должен быть выбран таким образом, чтобы сохранять контекст и структуру текста, минимизируя размерность и избыточность.
- **Метрики**: **accuracy**, **precision**, **recall**, **F1-score**.



## 4. Обучение модели: 
- Обучение классификатора (например, **логистической регрессии**, **наивного байесовского классификатора** или **случайного леса**) для предсказания наличия скиллов в тексте.
- **Метрики**: **accuracy**, **precision**, **recall**, **F1-score**.

## 5. Оценка модели:
- Оценка точности модели с использованием вышеупомянутых метрик. Результаты должны быть интерпретированы, чтобы понять, насколько хорошо модель различает скиллы от не скиллов.

## **Бейзлайн для этапа 2**:
Простой классификатор (например, **наивный байесовский классификатор** или **логистическая регрессия**) с точностью более **80%** на тестовых данных.

## 6. Риски и способы их снижения:
 
- **Переобучение**: Для предотвращения переобучения используется регуляризация и кросс-валидация.

## 7. Необходимый результат этапа:  
Обученная модель классификации с точностью более **80%** на тестовых данных.

---

# Этап 3: Обработка вакансий и предсказание требований

## 1. Загрузка и подготовка модели и векторизатора:
- Загрузка обученной модели классификации и **TF-IDF** векторизатора.
- **Требования**: правильная загрузка модели и векторизатора, чтобы предсказания были основаны на ранее обученных данных.

## 2. Обработка данных вакансий:
- Извлечение данных с сайта вакансии (парсинг URL).
- Парсинг ключевых навыков, описания вакансии, требований и других данных.
- **Требования**: данные вакансии должны быть корректно извлечены и готовы для анализа.

## 3. Предсказание наличия требований:
- Преобразование текста вакансии в числовой формат с использованием **TF-IDF**.
- Применение обученной модели для предсказания наличия скиллов в вакансиях.
- **Метрики**: **accuracy**, **precision**, **recall**, **F1-score**.

## 4. Постобработка и добавление результатов:
- Применение модели для предсказания, является ли каждый текст вакансии скиллами (обученный классификатор). 
- Каждый текст вакансии обрабатывается для выделения ключевых навыков и добавления предсказанных меток (1 - скиллы, 0 - не скиллы).
- Добавление этих предсказанных меток в итоговый словарь вакансий.
- Для каждой вакансии можно вывести список навыков, которые модель считает важными, и представить их в отдельной колонке.

## 5. Метрики расстояния:
- Для сопоставления вакансий с курсами можно использовать различные метрики расстояния, такие как:
  - **Косинусное расстояние** (Cosine distance)
  - **Евклидово расстояние** (Euclidean distance)
  - **Манхэттенское расстояние** (Manhattan distance)
  - **Жаккардова мера** (Jaccard similarity)

## 6. Нормализация и сортировка данных:
- Сортировка вакансий по общей схожести с курсами, чтобы определить, какие курсы наиболее соответствуют требованиям вакансий.
- **Требования**: сортировка должна быть выполнена так, чтобы вакансии с наибольшим сходством с курсами шли первыми.


## **Бейзлайн для этапа 3**:
Вывод наиболее схожих с вакансией курсов на основе вычисленных метрик расстояния (например, с использованием **косинусного расстояния**). 

## 7. Риски и способы их снижения:
- **Ошибки в извлечении информации**: Использование более стабильных методов парсинга и строгих фильтров для извлечения данных вакансий.
- **Низкая точность предсказаний**: Оптимизация модели и предобработки для повышения точности предсказаний, а также использование более точных методов классификации, например, **градиентного бустинга**.

## 8. Необходимый результат этапа:  
Итоговый DataFrame с вакансиями, отсортированными по схожести с курсами, для каждой вакансии предлагаются соответствующие курсы с наибольшим сходством.
Пример в `utils.py `


# Этап 4: Обучение модели для предсказания увеличения заработной платы после прохождения курса

## Подготовка данных для обучения

1. **Данные для обучения**:  
   Для обучения модели будет использован датасет `df_hh_res_all.csv`, который содержит информацию о навыках, требуемых для вакансий, и средних зарплатах для каждой вакансии. Важно, что каждая запись в датасете включает информацию о навыках, требуемых для вакансии, а также о средней зарплате, которая предлагается кандидатам, соответствующим этим навыкам.

2. **Предобработка данных**:
   - Преобразование категориальных признаков (например, тип вакансии, требования и прочее) в числовые признаки с использованием one-hot encoding или порядкового кодирования.
   - Преобразование навыков вакансий в числовые векторы с использованием методов, таких как TF-IDF или Word2Vec.
   - Обработка пропусков и стандартизация данных (нормализация числовых признаков).

3. **Целевая переменная**:  
   Для каждой вакансии будет предсказана зарплата кандидата, который пройдет курс и получит новые навыки. Целевая переменная — это **зарплата кандидата**, которая будет зависеть от набора навыков, требуемых для вакансии, и дополнительных навыков, приобретенных после курса.

## Обучение модели

1. **Выбор модели**:  
   Модель будет обучена для предсказания зарплаты с учетом текущих навыков, требуемых для вакансии, и будущих навыков, которые кандидат может приобрести после прохождения курса. Для начального этапа обучения будет использована **линейная регрессия** как базовая модель. В дальнейшем, если точность модели окажется недостаточной, можно будет перейти к более сложным моделям, таким как **градиентный бустинг** (например, XGBoost) или **нейронные сети**.

2. **Метрики**:  
   Для оценки качества модели будут использованы следующие метрики:
   - **MSE (Mean Squared Error)**: Среднеквадратичная ошибка, которая будет измерять величину расхождения предсказанных значений зарплаты с реальными.
   - **MAE (Mean Absolute Error)**: Средняя абсолютная ошибка, которая дает представление о средней ошибке предсказания.

3. **Процесс обучения**:  
   - Обучение модели будет проводиться на данных, где каждой записи о вакансии соответствуют прогнозируемые значения зарплаты для кандидатов.
   - Для каждой вакансии будут созданы два прогноза: один для текущих навыков (предикт для навыков, указанных в резюме кандидата) и второй для прогнозируемых навыков после прохождения курса (предикт для дополнительных навыков).
   - Модель будет обучаться с использованием кросс-валидации для предотвращения переобучения.

## Интеграция модели в приложение

1. **Интеграция**:  
   После обучения модель будет интегрирована в приложение, которое будет предсказывать зарплату кандидата, учитывая как текущие навыки, требуемые для вакансии, так и дополнительные навыки, приобретенные после прохождения курса.
   
2. **Прирост зарплаты**:  
   Для каждого кандидата будет вычисляться прирост зарплаты путем вычитания предсказанных значений для текущих и будущих навыков. То есть, сначала будет сделан прогноз на основе текущих навыков кандидата, затем прогноз для дополнительных навыков, которые он получит после курса. Разница между этими двумя предсказаниями и будет составлять прирост в зарплате.

3. **Корректность интеграции**:  
   Важно обеспечить правильную интеграцию модели в приложение, чтобы она могла делать предсказания в реальном времени и обеспечивала стабильную работу.

## Анализ и интерпретация работы модели

1. **Методы интерпретации**:
   Для анализа важности признаков можно использовать такие методы, как **SHAP** или **LIME**, чтобы понять, какие навыки оказывают наибольшее влияние на прогнозируемую зарплату кандидата.

2. **Метрики интерпретации**:
   - **Ошибка модели**: Оценка точности предсказания.
   - **Влияние признаков**: Анализ того, какие именно навыки или характеристики вакансии влияют на увеличение зарплаты.

## Бейзлайн для этапа 4

- На первом этапе будет использоваться **линейная регрессия** как базовый метод для прогнозирования зарплаты, с точностью предсказания, достигающей **85%**. В случае неудовлетворительных результатов можно будет перейти к более сложным моделям, таким как **градиентный бустинг** или **нейронные сети**.

## Риски и способы их снижения

1. **Переобучение**:  
   Для предотвращения переобучения будет использована **кросс-валидация** и методы **регуляризации** (например, L1/L2-регуляризация).
   
2. **Низкая точность прогноза**:  
   Если точность модели окажется недостаточной, будет проведен переход к более сложным моделям, таким как **градиентный бустинг** или **нейронные сети**.

## Необходимый результат этапа

1. **Обученная и интегрированная модель**, которая предсказывает зарплату кандидата с текущими и будущими навыками и вычисляет прирост зарплаты.
2. **Интегрированная модель в приложение** с точностью прогноза **более 85%**.
3. **Отчёт о результатах предсказания** с интерпретацией значимости признаков, влияющих на зарплату, и прирост зарплаты после обучения.

# Конечный результат для пользователя:
- Если пользователь загружает вакансию, ему будет предложен подходящий курс для обучения.
- Если пользователь дополнительно загружает резюме, система рассчитает прирост в зарплате для наиболее подходящего курса, основываясь на навыках, указанных в резюме, и навыках, которые можно будет получить после прохождения курса.






















































